<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tech note of @xingelf</title>
    <link>https://xingelf.github.io/mlai/</link>
    <description>Recent content on Tech note of @xingelf</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 20 Mar 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://xingelf.github.io/mlai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Information Theory</title>
      <link>https://xingelf.github.io/mlai/entropy/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/entropy/</guid>
      <description>Purpose: To understand the basics of information theory. Information Quantity When the probability of event A occurring is denoted as P(A), the information quantity I(A) is defined as follows.&#xA;$ I(A) = -\log P(A)$&#xA;The smaller the probability, the greater the information quantity. It is easy to remember that rare events have a greater impact (information).&#xA;The following characteristics apply to probability P(A).&#xA;It increases when the probability is small. In the case of multiple independent events, the information quantity is represented by their sum (probabilities are represented by products).</description>
    </item>
    <item>
      <title>Softmax Function</title>
      <link>https://xingelf.github.io/mlai/softmax/</link>
      <pubDate>Sat, 16 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/softmax/</guid>
      <description>Softmax Function The softmax function is a mathematical function that converts a vector of numbers into a probability distribution. It is defined by the following equation.&#xA;$ y_i = {softmax}(x_i) = \frac{e^{x_i}}{\sum_{k=1}e^{x_i}}$&#xA;$ i = 0,1,2,\dots n$&#xA;When all $y_i$ values are summed, the total is always 1, which allows the output to be interpreted as probabilities. This property makes softmax particularly useful in multi-class classification problems.&#xA;One important property of the softmax function is that it remains unchanged when a constant value is added to all elements of the input vector, as shown by the equation:</description>
    </item>
    <item>
      <title>Python a Function Convert Percentage in String/Object Type Columns to Numbers</title>
      <link>https://xingelf.github.io/mlai/str_to_rate/</link>
      <pubDate>Sat, 29 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/str_to_rate/</guid>
      <description>Converts percentage information given in String/Object type columns into numbers.&#xA;def str_to_rate(s): if pd.isnull(s) == False: return float(s.replace(&amp;#39;%&amp;#39;, &amp;#39;&amp;#39;)) else: return s Usage:&#xA;col = &amp;#34;ReplyRate&amp;#34; df[col] = df[col].apply(str_to_rate) </description>
    </item>
    <item>
      <title>Python a small Function Convert Boolean Characters to Boolean Type in String/Object Columns</title>
      <link>https://xingelf.github.io/mlai/str_to_bool/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/str_to_bool/</guid>
      <description>Converts boolean characters to boolean type if provided as &amp;rsquo;t&amp;rsquo; or &amp;lsquo;f&amp;rsquo; in String/Object type columns.&#xA;def str_to_bool(s): if s == &amp;#39;t&amp;#39;: return True else: return False Usage&#xA;col = &amp;#34;Availability&amp;#34; df[col] = df[col].apply(str_to_bool) </description>
    </item>
    <item>
      <title>Model Evaluation in ML</title>
      <link>https://xingelf.github.io/mlai/evalmodel/</link>
      <pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/evalmodel/</guid>
      <description>Model Evaluation Definition of Data in Model Evaluation Training Set: Data used for training machine learning models. Validation Set: Data used for adjusting hyperparameters, etc. Test Set: Data used to estimate generalization performance -&amp;gt; Final evaluation of the model. Holdout Method, k-Fold Cross-Validation Evaluation methods for models on given data. Holdout Method: A method of dividing the data set into two parts, using one for training and the other for testing evaluation metrics. It is common to split the training</description>
    </item>
  </channel>
</rss>
