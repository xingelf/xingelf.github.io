<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Try Harder</title>
    <link>https://xingelf.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Try Harder</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://xingelf.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Softmax Function 🔢</title>
      <link>https://xingelf.github.io/mlai/softmax/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/softmax/</guid>
      <description>&lt;h2 id=&#34;overview-&#34;&gt;Overview 📝&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the Softmax function, a crucial component in machine learning. The Softmax function transforms arbitrary real-valued vectors into probability distributions, making it essential for multi-class classification problems. We&amp;rsquo;ll dive into its fundamental mechanisms, mathematical definition, key properties, and practical applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Small Python Function to Convert &#39;t&#39;/&#39;f&#39; Strings to Boolean Type</title>
      <link>https://xingelf.github.io/mlai/str_to_bool/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/str_to_bool/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;In data analysis and machine learning, it is common to encounter datasets where boolean values are represented as strings like &lt;code&gt;&#39;t&#39;&lt;/code&gt; (true) or &lt;code&gt;&#39;f&#39;&lt;/code&gt; (false). Converting these to Python&amp;rsquo;s &lt;code&gt;True&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt; types makes subsequent processing and analysis much smoother. This article explains a simple function for this conversion and how to use it effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Complete Guide to Machine Learning Model Evaluation Methods</title>
      <link>https://xingelf.github.io/mlai/eval_model/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/eval_model/</guid>
      <description>&lt;h2 id=&#34;core-data-concepts-in-model-evaluation-&#34;&gt;Core Data Concepts in Model Evaluation 📊&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Training Set:&lt;/strong&gt; Dataset used to train machine learning models (parameter optimization)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Validation Set:&lt;/strong&gt; Dataset used for hyperparameter tuning and model selection during development&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Test Set:&lt;/strong&gt; Dataset reserved exclusively for assessing generalization performance → Used for final model evaluation &lt;em&gt;after&lt;/em&gt; development completion&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;evaluation-methodologies&#34;&gt;Evaluation Methodologies&lt;/h2&gt;&#xA;&lt;h3 id=&#34;holdout-method&#34;&gt;Holdout Method&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Randomly splits the dataset into two mutually exclusive subsets:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Typical split:&lt;/strong&gt; 80% training / 20% testing (ratio varies by use case)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strengths:&lt;/strong&gt; Computationally efficient, simple implementation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Limitations:&lt;/strong&gt; High variance in performance estimates with small datasets&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;k-fold-cross-validation&#34;&gt;k-Fold Cross-Validation&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Systematic evaluation protocol:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Partition dataset into &lt;em&gt;k&lt;/em&gt; equal-sized folds&lt;/li&gt;&#xA;&lt;li&gt;Iteratively use each fold as validation set while training on remaining &lt;em&gt;k-1&lt;/em&gt; folds&lt;/li&gt;&#xA;&lt;li&gt;Aggregate results (mean ± standard deviation) across all folds&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Advantages:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reduces variance in performance estimates&lt;/li&gt;&#xA;&lt;li&gt;Maximizes data utilization (critical for small datasets)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Common Variants:&lt;/strong&gt; Stratified k-fold (preserves class distribution)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;leave-one-out-cross-validation-loocv&#34;&gt;Leave-One-Out Cross-Validation (LOOCV)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extreme case of k-fold where &lt;em&gt;k = n&lt;/em&gt; (number of samples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Case:&lt;/strong&gt; Small-scale datasets with &amp;lt;100 samples&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tradeoff:&lt;/strong&gt; Computationally prohibitive for large &lt;em&gt;n&lt;/em&gt; (requires &lt;em&gt;n&lt;/em&gt; model fits)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Understanding Entropy and Information Theory in Machine Learning</title>
      <link>https://xingelf.github.io/mlai/entropy/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/entropy/</guid>
      <description>&lt;h2 id=&#34;introduction-&#34;&gt;Introduction 📚&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the fundamental concepts of information theory, which form the mathematical foundation for many machine learning algorithms. Understanding these concepts is crucial for grasping how models process and learn from data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Function: Convert Percentage Strings to Numbers</title>
      <link>https://xingelf.github.io/mlai/str_to_rate/</link>
      <pubDate>Sat, 29 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/str_to_rate/</guid>
      <description>&lt;p&gt;Easily convert percentage values stored as strings (e.g., &amp;ldquo;85%&amp;rdquo;) into numeric values for analysis in Python! 🚀&lt;/p&gt;</description>
    </item>
    <item>
      <title>書籍 Kaggleで勝つデータ分析</title>
      <link>https://xingelf.github.io/tech/kaggle/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/tech/kaggle/</guid>
      <description>&lt;h2 id=&#34;書籍-kaggleで勝つデータ分析---門脇-大輔&#34;&gt;書籍 Kaggleで勝つデータ分析   門脇 大輔&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;良い点：網羅的、リファレンス多数&lt;/li&gt;&#xA;&lt;li&gt;注意点：精読が必要、中級者向け&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/dp/B07YTDBC3Z/&#34;&gt;https://www.amazon.co.jp/dp/B07YTDBC3Z/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;概要&#34;&gt;&lt;strong&gt;概要&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;書籍「Kaggleで勝つデータ分析」は、データサイエンスコンペティションサイトKaggleで上位入賞を果たしている著者が、勝つためのデータ分析の技術とノウハウを解説した書籍です。&lt;/p&gt;&#xA;&lt;h3 id=&#34;内容&#34;&gt;&lt;strong&gt;内容&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;本書では、データ分析の基礎知識から、Kaggleで実際に使用される機械学習モデルや前処理の手法、コンペティションに臨むための戦略まで、幅広く解説されています。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
