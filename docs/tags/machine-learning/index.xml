<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Try Harder</title>
    <link>https://xingelf.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Try Harder</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://xingelf.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Softmax Function ğŸ”¢</title>
      <link>https://xingelf.github.io/mlai/softmax/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/softmax/</guid>
      <description>&lt;h2 id=&#34;overview-&#34;&gt;Overview ğŸ“&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the Softmax function, a crucial component in machine learning. The Softmax function transforms arbitrary real-valued vectors into probability distributions, making it essential for multi-class classification problems. We&amp;rsquo;ll dive into its fundamental mechanisms, mathematical definition, key properties, and practical applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Odds Ratio and Risk Ratio</title>
      <link>https://xingelf.github.io/tech/odds-risk/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/tech/odds-risk/</guid>
      <description>&lt;h1 id=&#34;-understanding-odds-ratio-and-risk-ratio&#34;&gt;ğŸ“Š Understanding Odds Ratio and Risk Ratio&lt;/h1&gt;&#xA;&lt;h2 id=&#34;-what-is-risk-ratio&#34;&gt;ğŸ¯ What is Risk Ratio?&lt;/h2&gt;&#xA;&lt;p&gt;Risk Ratio is a measure that represents the ratio of risks (incidence rates) between two groups. Let&amp;rsquo;s explain using hypothetical data:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Complete Guide to Machine Learning Model Evaluation Methods</title>
      <link>https://xingelf.github.io/mlai/eval_model/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/eval_model/</guid>
      <description>&lt;h2 id=&#34;core-data-concepts-in-model-evaluation-&#34;&gt;Core Data Concepts in Model Evaluation ğŸ“Š&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Training Set:&lt;/strong&gt; Dataset used to train machine learning models (parameter optimization)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Validation Set:&lt;/strong&gt; Dataset used for hyperparameter tuning and model selection during development&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Test Set:&lt;/strong&gt; Dataset reserved exclusively for assessing generalization performance â†’ Used for final model evaluation &lt;em&gt;after&lt;/em&gt; development completion&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;evaluation-methodologies&#34;&gt;Evaluation Methodologies&lt;/h2&gt;&#xA;&lt;h3 id=&#34;holdout-method&#34;&gt;Holdout Method&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Randomly splits the dataset into two mutually exclusive subsets:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Typical split:&lt;/strong&gt; 80% training / 20% testing (ratio varies by use case)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strengths:&lt;/strong&gt; Computationally efficient, simple implementation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Limitations:&lt;/strong&gt; High variance in performance estimates with small datasets&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;k-fold-cross-validation&#34;&gt;k-Fold Cross-Validation&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Systematic evaluation protocol:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Partition dataset into &lt;em&gt;k&lt;/em&gt; equal-sized folds&lt;/li&gt;&#xA;&lt;li&gt;Iteratively use each fold as validation set while training on remaining &lt;em&gt;k-1&lt;/em&gt; folds&lt;/li&gt;&#xA;&lt;li&gt;Aggregate results (mean Â± standard deviation) across all folds&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Advantages:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reduces variance in performance estimates&lt;/li&gt;&#xA;&lt;li&gt;Maximizes data utilization (critical for small datasets)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Common Variants:&lt;/strong&gt; Stratified k-fold (preserves class distribution)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;leave-one-out-cross-validation-loocv&#34;&gt;Leave-One-Out Cross-Validation (LOOCV)&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extreme case of k-fold where &lt;em&gt;k = n&lt;/em&gt; (number of samples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Case:&lt;/strong&gt; Small-scale datasets with &amp;lt;100 samples&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tradeoff:&lt;/strong&gt; Computationally prohibitive for large &lt;em&gt;n&lt;/em&gt; (requires &lt;em&gt;n&lt;/em&gt; model fits)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Understanding Entropy and Information Theory in Machine Learning</title>
      <link>https://xingelf.github.io/mlai/entropy/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/entropy/</guid>
      <description>&lt;h2 id=&#34;introduction-&#34;&gt;Introduction ğŸ“š&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the fundamental concepts of information theory, which form the mathematical foundation for many machine learning algorithms. Understanding these concepts is crucial for grasping how models process and learn from data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>æ©Ÿæ¢°å­¦ç¿’å‰å‡¦ç†</title>
      <link>https://xingelf.github.io/tech/_pre-edit/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/tech/_pre-edit/</guid>
      <description>&lt;h1 id=&#34;å‰å‡¦ç†&#34;&gt;å‰å‡¦ç†&lt;/h1&gt;&#xA;&lt;p&gt;æ©Ÿæ¢°å­¦ç¿’ã¯å‰å‡¦ç†ãŒ8å‰²ã¨è¨€ã‚ã‚Œã¾ã™ã€‚å‰å‡¦ç†ã®æ‰‹æ³•ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;æ¬ æå€¤ã®å‡¦ç†&#34;&gt;æ¬ æå€¤ã®å‡¦ç†&lt;/h2&gt;&#xA;&lt;p&gt;ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨æ•°å­—ãŒblankã§ã‚ã‚‹å ´åˆã€è©²å½“ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã€ã¾ãŸã¯ã€ä»£æ›¿å€¤ã§è£œå®Œã—ã¾ã™ã€‚&#xA;ã©ã®ã‚ˆã†ã«æ¬ æå€¤ã‚’æ‰±ã†ã‹ãŒãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚&#xA;å‡¦ç†ã¨ã—ã¦ã¯ã€fillna,dropnaãªã©ã®é–¢æ•°ã§ç°¡å˜ã«å¯¾å‡¦å¯èƒ½ã§ã™ã€‚&lt;/p&gt;&#xA;&lt;h3 id=&#34;æ¬ æå€¤ã®ç¢ºèª&#34;&gt;æ¬ æå€¤ã®ç¢ºèª&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;df.isnull.sum()&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;æ¬ æå€¤ã®å¯¾å¿œ&#34;&gt;æ¬ æå€¤ã®å¯¾å¿œ&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;å¹³å‡å€¤ã§è£œå®Œ&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;df = df.fillna(df.mean())&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;ä¸­å¤®å€¤ã§è£œå®Œ&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;df = df.fillna(df.mean())&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;æœ€ç…©å€¤ã§è£œå®Œ&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;df = df.fillna(df.mode())&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;æ¬ æãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤&#34;&gt;æ¬ æãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤&lt;/h3&gt;&#xA;&lt;p&gt;dropnaã§å‰Šé™¤ã™ã‚‹å ´åˆ&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
