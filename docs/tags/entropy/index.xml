<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Entropy on Try Harder</title>
    <link>https://xingelf.github.io/tags/entropy/</link>
    <description>Recent content in Entropy on Try Harder</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 20 Mar 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://xingelf.github.io/tags/entropy/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Understanding Entropy and Information Theory in Machine Learning</title>
      <link>https://xingelf.github.io/mlai/entropy/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/entropy/</guid>
      <description>&lt;h2 id=&#34;introduction-&#34;&gt;Introduction ðŸ“š&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the fundamental concepts of information theory, which form the mathematical foundation for many machine learning algorithms. Understanding these concepts is crucial for grasping how models process and learn from data.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
