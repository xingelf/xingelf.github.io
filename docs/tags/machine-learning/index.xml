<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Try Harder</title>
    <link>https://xingelf.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Try Harder</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://xingelf.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Softmax Function ğŸ”¢</title>
      <link>https://xingelf.github.io/mlai/softmax/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/softmax/</guid>
      <description>&lt;h2 id=&#34;overview-&#34;&gt;Overview ğŸ“&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the Softmax function, a crucial component in machine learning. The Softmax function transforms arbitrary real-valued vectors into probability distributions, making it essential for multi-class classification problems. We&amp;rsquo;ll dive into its fundamental mechanisms, mathematical definition, key properties, and practical applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Odds Ratio and Risk Ratio</title>
      <link>https://xingelf.github.io/tech/odds-risk/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/tech/odds-risk/</guid>
      <description>&lt;h1 id=&#34;-understanding-odds-ratio-and-risk-ratio&#34;&gt;ğŸ“Š Understanding Odds Ratio and Risk Ratio&lt;/h1&gt;&#xA;&lt;h2 id=&#34;-what-is-risk-ratio&#34;&gt;ğŸ¯ What is Risk Ratio?&lt;/h2&gt;&#xA;&lt;p&gt;Risk Ratio is a measure that represents the ratio of risks (incidence rates) between two groups. Let&amp;rsquo;s explain using hypothetical data:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Evaluation in ML</title>
      <link>https://xingelf.github.io/mlai/eval_model/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/eval_model/</guid>
      <description>&lt;h2 id=&#34;core-data-concepts-in-model-evaluation&#34;&gt;&lt;strong&gt;Core Data Concepts in Model Evaluation&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Training Set:&lt;/strong&gt; Dataset used to train machine learning models (parameter optimization).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Validation Set:&lt;/strong&gt; Dataset used for hyperparameter tuning and model selection during development.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Test Set:&lt;/strong&gt; Dataset reserved exclusively for assessing generalization performance â†’ Used for final model evaluation &lt;em&gt;after&lt;/em&gt; development completion.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;evaluation-methodologies&#34;&gt;&lt;strong&gt;Evaluation Methodologies&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;holdout-method&#34;&gt;&lt;strong&gt;Holdout Method&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Randomly splits the dataset into two mutually exclusive subsets:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Typical split:&lt;/strong&gt; 80% training / 20% testing (ratio varies by use case)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strengths:&lt;/strong&gt; Computationally efficient, simple implementation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Limitations:&lt;/strong&gt; High variance in performance estimates with small datasets&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;k-fold-cross-validation&#34;&gt;&lt;strong&gt;k-Fold Cross-Validation&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Systematic evaluation protocol:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Partition dataset into &lt;em&gt;k&lt;/em&gt; equal-sized folds&lt;/li&gt;&#xA;&lt;li&gt;Iteratively use each fold as validation set while training on remaining &lt;em&gt;k-1&lt;/em&gt; folds&lt;/li&gt;&#xA;&lt;li&gt;Aggregate results (mean Â± standard deviation) across all folds&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Advantages:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reduces variance in performance estimates&lt;/li&gt;&#xA;&lt;li&gt;Maximizes data utilization (critical for small datasets)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Common Variants:&lt;/strong&gt; Stratified k-fold (preserves class distribution)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;leave-one-out-cross-validation-loocv&#34;&gt;&lt;strong&gt;Leave-One-Out Cross-Validation (LOOCV)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extreme case of k-fold where &lt;em&gt;k = n&lt;/em&gt; (number of samples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Case:&lt;/strong&gt; Small-scale datasets with &amp;lt;100 samples&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tradeoff:&lt;/strong&gt; Computationally prohibitive for large &lt;em&gt;n&lt;/em&gt; (requires &lt;em&gt;n&lt;/em&gt; model fits)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>æ©Ÿæ¢°å­¦ç¿’å‰å‡¦ç†</title>
      <link>https://xingelf.github.io/tech/_pre-edit/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/tech/_pre-edit/</guid>
      <description>&lt;h1 id=&#34;å‰å‡¦ç†&#34;&gt;å‰å‡¦ç†&lt;/h1&gt;&#xA;&lt;p&gt;æ©Ÿæ¢°å­¦ç¿’ã¯å‰å‡¦ç†ãŒ8å‰²ã¨è¨€ã‚ã‚Œã¾ã™ã€‚å‰å‡¦ç†ã®æ‰‹æ³•ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
