<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Try Harder</title>
    <link>https://xingelf.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Try Harder</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 16 Dec 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://xingelf.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Softmax Function 🔢</title>
      <link>https://xingelf.github.io/mlai/softmax/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/softmax/</guid>
      <description>&lt;h2 id=&#34;overview-&#34;&gt;Overview 📝&lt;/h2&gt;&#xA;&lt;p&gt;This article explores the Softmax function, a crucial component in machine learning. The Softmax function transforms arbitrary real-valued vectors into probability distributions, making it essential for multi-class classification problems. We&amp;rsquo;ll dive into its fundamental mechanisms, mathematical definition, key properties, and practical applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Small Python Function to Convert &#39;t&#39;/&#39;f&#39; Strings to Boolean Type</title>
      <link>https://xingelf.github.io/mlai/str_to_bool/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/str_to_bool/</guid>
      <description>&lt;h1 id=&#34;overview&#34;&gt;Overview&lt;/h1&gt;&#xA;&lt;p&gt;In data analysis and machine learning, it is common to encounter datasets where boolean values are represented as strings like &lt;code&gt;&#39;t&#39;&lt;/code&gt; (true) or &lt;code&gt;&#39;f&#39;&lt;/code&gt; (false). Converting these to Python&amp;rsquo;s &lt;code&gt;True&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt; types makes subsequent processing and analysis much smoother. This article explains a simple function for this conversion and how to use it effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Evaluation in ML</title>
      <link>https://xingelf.github.io/mlai/eval_model/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/eval_model/</guid>
      <description>&lt;h2 id=&#34;core-data-concepts-in-model-evaluation&#34;&gt;&lt;strong&gt;Core Data Concepts in Model Evaluation&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Training Set:&lt;/strong&gt; Dataset used to train machine learning models (parameter optimization).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Validation Set:&lt;/strong&gt; Dataset used for hyperparameter tuning and model selection during development.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Test Set:&lt;/strong&gt; Dataset reserved exclusively for assessing generalization performance → Used for final model evaluation &lt;em&gt;after&lt;/em&gt; development completion.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;evaluation-methodologies&#34;&gt;&lt;strong&gt;Evaluation Methodologies&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;holdout-method&#34;&gt;&lt;strong&gt;Holdout Method&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Randomly splits the dataset into two mutually exclusive subsets:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Typical split:&lt;/strong&gt; 80% training / 20% testing (ratio varies by use case)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Strengths:&lt;/strong&gt; Computationally efficient, simple implementation&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Limitations:&lt;/strong&gt; High variance in performance estimates with small datasets&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;k-fold-cross-validation&#34;&gt;&lt;strong&gt;k-Fold Cross-Validation&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Systematic evaluation protocol:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Partition dataset into &lt;em&gt;k&lt;/em&gt; equal-sized folds&lt;/li&gt;&#xA;&lt;li&gt;Iteratively use each fold as validation set while training on remaining &lt;em&gt;k-1&lt;/em&gt; folds&lt;/li&gt;&#xA;&lt;li&gt;Aggregate results (mean ± standard deviation) across all folds&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Advantages:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Reduces variance in performance estimates&lt;/li&gt;&#xA;&lt;li&gt;Maximizes data utilization (critical for small datasets)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Common Variants:&lt;/strong&gt; Stratified k-fold (preserves class distribution)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;leave-one-out-cross-validation-loocv&#34;&gt;&lt;strong&gt;Leave-One-Out Cross-Validation (LOOCV)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extreme case of k-fold where &lt;em&gt;k = n&lt;/em&gt; (number of samples)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Case:&lt;/strong&gt; Small-scale datasets with &amp;lt;100 samples&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tradeoff:&lt;/strong&gt; Computationally prohibitive for large &lt;em&gt;n&lt;/em&gt; (requires &lt;em&gt;n&lt;/em&gt; model fits)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Information Theory</title>
      <link>https://xingelf.github.io/mlai/entropy/</link>
      <pubDate>Wed, 20 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/entropy/</guid>
      <description>&lt;p&gt;Purpose: To understand the basics of information theory.&lt;/p&gt;&#xA;&lt;h2 id=&#34;information-quantity&#34;&gt;Information Quantity&lt;/h2&gt;&#xA;&lt;p&gt;When the probability of event A occurring is denoted as P(A), the information quantity I(A) is defined as follows.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Function: Convert Percentage Strings to Numbers</title>
      <link>https://xingelf.github.io/mlai/str_to_rate/</link>
      <pubDate>Sat, 29 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/mlai/str_to_rate/</guid>
      <description>&lt;p&gt;Easily convert percentage values stored as strings (e.g., &amp;ldquo;85%&amp;rdquo;) into numeric values for analysis in Python! 🚀&lt;/p&gt;</description>
    </item>
    <item>
      <title>書籍 Kaggleで勝つデータ分析</title>
      <link>https://xingelf.github.io/tech/kaggle/</link>
      <pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://xingelf.github.io/tech/kaggle/</guid>
      <description>&lt;h2 id=&#34;書籍-kaggleで勝つデータ分析---門脇-大輔&#34;&gt;書籍 Kaggleで勝つデータ分析   門脇 大輔&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;良い点：網羅的、リファレンス多数&lt;/li&gt;&#xA;&lt;li&gt;注意点：精読が必要、中級者向け&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/dp/B07YTDBC3Z/&#34;&gt;https://www.amazon.co.jp/dp/B07YTDBC3Z/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;概要&#34;&gt;&lt;strong&gt;概要&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;書籍「Kaggleで勝つデータ分析」は、データサイエンスコンペティションサイトKaggleで上位入賞を果たしている著者が、勝つためのデータ分析の技術とノウハウを解説した書籍です。&lt;/p&gt;&#xA;&lt;h3 id=&#34;内容&#34;&gt;&lt;strong&gt;内容&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;本書では、データ分析の基礎知識から、Kaggleで実際に使用される機械学習モデルや前処理の手法、コンペティションに臨むための戦略まで、幅広く解説されています。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
